# ðŸš€ AFM DevSecOps Project
### **Portfolio by Swapnil Gavhale**
-----------------------------------------------------------------------------
## ðŸ”° Overview
The **AFM (App Feature / Microservice) Project** is a **constraint-driven DevSecOps portfolio**, designed to demonstrate **how real DevOps platforms are designed, evolved, secured, and operated** â€” not just how individual tools are used.
Unlike typical demo projects, AFM intentionally focuses on:
- **Architecture & design decisions**
- **Trade-offs under constraints**
- **Failures, bottlenecks, and recovery**
- **Cost-aware engineering**
- **Operational realism**

The platform was built **incrementally**, validated at each stage, and later migrated to Kubernetes using **production-grade DevOps practices**.

---
## 1ï¸âƒ£ Problem Statement & Motivation
Most publicly available DevOps projects focus on **tool demonstrations**, such as:
- Running containers
- Simple CI pipelines
- One-click Kubernetes setups

However, **real DevOps roles** require engineers to:
- Design systems under constraints
- Make architectural decisions
- Handle failures and incidents
- Balance **cost, security, and scalability**    
- Operate platforms with **limited resources**

### Motivation Behind AFM
The AFM project was created to:
- Simulate **enterprise-grade DevOps challenges**
- Build systems **incrementally**, not ideally
- Follow a realistic journey:  
    **Start small â†’ evolve â†’ migrate â†’ optimize**
- Document **why decisions were taken**, not just _what was implemented_

The project intentionally embraces real-world constraints:
- Limited budget
- No DNS / domain
- Single-node Kubernetes cluster
- Real pipeline failures
- Hybrid manual + automated workflows

---------------=======================================================------------------------------------------

## 2ï¸âƒ£ Architecture Choice â€“ Why Microservices?

Microservices were chosen to expose **real CI/CD, security, and Kubernetes complexity**, not theoretical scalability.
### Why Microservices Instead of a Monolith?
Microservices enable:
- Independent build & deploy
- Service isolation
- Kubernetes-native workflows
- Real ingress & routing scenarios
- Non-trivial CI/CD orchestration

This closely mirrors how **Banking and enterprise platforms** are actually built and operated.
--------------------------------------------------------------------------------------------------
## 3ï¸âƒ£ AFM Scope â€“ Why Only 4 Microservices?
The project deliberately limits scope to **four AFMs**, prioritizing **depth over breadth**.

### Selected AFMs
1. **Auth Service**
2. **Registration Service**
3. **Login Service**
4. **Frontend UI (separate microservice)**

### Why This Split?
- **Auth / Login / Registration**
    - Represent real identity and access workflows in banking systems
- **Frontend UI as a separate microservice**
    - Independent UI releases
    - Backend changes without UI rebuild
    - Real ingress routing use cases

This is **controlled realism**, not over-engineering.

---
## 4ï¸âƒ£ Technology Choices â€“ Why These Tools?
### Backend â€“ Spring Boot (Java)
Chosen because:
- Widely used in enterprise & banking systems
- Mature ecosystem
- Strong tooling support
- Easy observability & security integration

### Frontend â€“ HTML / CSS
Chosen intentionally to:
- Keep focus on **DevOps**, not frontend frameworks
- Enable fast iteration
- Simplify containerization
- Clearly demonstrate ingress routing

---
## 5ï¸âƒ£ AWS as the Cloud Platform

AWS was selected to reflect **real enterprise adoption patterns**.
### AWS Services Used & Purpose
- **EC2** â€“ GitLab CI/CD runner & initial hosting
- **S3** â€“ Terraform remote state
- **DynamoDB** â€“ Terraform state locking
- **ECR** â€“ Container image registry
- **IAM** â€“ Fine-grained access control
- **CloudWatch** â€“ Infrastructure & cluster observability
- **RDS** â€“ Persistent production-style database
- **EKS** â€“ Kubernetes orchestration

---

## 6ï¸âƒ£ Infrastructure as Code â€“ Terraform Design
Infrastructure is managed **entirely via Terraform**, following enterprise IaC standards.
### Key Terraform Practice
- Modular design
- Environment-aware structure
- Remote state via S3
- DynamoDB state locking
- No local `terraform apply`
- All infrastructure changes via CI/CD only

This ensures:
- Reproducibility
- Auditability
- Safe team workflows

---
## 7ï¸âƒ£ Infrastructure Automation â€“ GitLab CI/CD
All infrastructure provisioning is executed **exclusively via GitLab pipelines**.
### Terraform Lifecycle in CI/CD
- **Validate** â€“ Syntax & configuration checks
- **Plan** â€“ Change preview
- **Apply** â€“ Manual approval required
- **Post-Provision** â€“ ALB Controller installation
- **Destroy** â€“ Isolated, manual teardown

This mirrors **real platform-engineering workflows**.

---
## 8ï¸âƒ£ EKS Cluster Design â€“ Intentional Constraints
### Why a Single-Node EKS Cluster?
- Instance type: **t3.medium**
- Managed node group
- Cost-efficient
- Forces capacity planning
- Exposes real scheduling challenges

> Single-node EKS is **harder**, not easier â€” and that was intentional.

---
## 9ï¸âƒ£ Networking & Region Decisions
### Why Default VPC?
- Reduced networking complexity
- Avoided over-engineering
- Focus stayed on Kubernetes, CI/CD, and IaC

### Why `us-east-1`?
- Broad AWS service availability
- Cost-effective
- Faster access to new AWS features
- Enterprise-standard region

---

## ðŸ”Ÿ Database Evolution â€“ user.json â†’ Amazon RDS
### Initial State
- Local `/data/user.json`
- Simple and fast for early validation

### Final State
- Amazon RDS (`db.t3.micro`)
- Shared backend for all AFMs
- Persistent, production-style storage
- Monitored via CloudWatch

---

## 1ï¸âƒ£1ï¸âƒ£ Container Registry â€“ Why Amazon ECR?
Amazon ECR was chosen over GitLab / GitHub registries due to:
- Native AWS integration
- IAM-based authentication
- Seamless EKS image pulls
- Built-in vulnerability scanning
- Production suitability
---
## 1ï¸âƒ£2ï¸âƒ£ HTTPS & Ingress Journey
### Docker Compose Phase
- NGINX
- Self-signed certificates
- HTTPS enabled locally

### EKS Phase
- Migrated to **AWS Load Balancer Controller**
- Self-signed certs not supported by ALB
- ACM not used due to lack of DNS
- Operated over HTTP

### Why ALB Controller?
- Legacy EKS ingress controller deprecated (March 2026)
- AWS-recommended, future-proof solution
- Native AWS integration
- IRSA support
- Managed load balancers
---
## 1ï¸âƒ£3ï¸âƒ£ GitLab CI/CD Runner Design
- Single EC2 self-hosted runner
- Full Docker daemon control
- Terraform + Docker + EKS deployments
### Disk Expansion Learning
- Initial disk: 8 GB
- Expanded to 20 GB due to Docker layers, plugins, artifacts

Demonstrates **real operational learning**.
---

## 1ï¸âƒ£4ï¸âƒ£ Secrets Management Strategy
### Current State
- Secrets stored in **GitLab CI/CD variables**
- Masked & protected
- No hard-coded credentials

### Future Plan
- AWS Secrets Manager
- AWS KMS
- IRSA-based access

---
## 1ï¸âƒ£5ï¸âƒ£ Observability Strategy
### Tools Used

- **CloudWatch** â€“ Infra & control plane
- **Prometheus** â€“ Kubernetes & service metrics
- **Grafana** â€“ Visualization & debugging

### Real Challenge Faced
- Single node could not schedule 17 pods
- Solution:
    - Reduced AFM replicas
    - Optimized observability footprint
    - Restored stability

---
## ðŸ”š Final Takeaway
> The AFM platform was built **under real constraints**, evolved through failures, and refined using automation, security, and observability â€” exactly how production DevOps systems are built.

This portfolio demonstrates:
- DevOps mindset
- Terraform & Kubernetes maturity
- CI/CD discipline
- DevSecOps integration
- Cost-aware engineering
- Future-ready platform thinking
- Ready for GitOps as we have used Gitlab Ci/CD
