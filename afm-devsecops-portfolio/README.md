
## 1ï¸âƒ£ Problem Statement & Motivation
Most DevOps learning projects available publicly focus on **tool demonstrations**, not **system thinking**.  
They usually stop at:
- Running containers
- Simple CI pipelines
- One-click Kubernetes deployments

However, real DevOps roles require engineers to:
- Make **design decisions**
- Handle **constraints**
- Face **failures**
- Balance **cost, security, and scalability**
- Operate systems with **limited resources**

### Motivation Behind AFM
The **AFM (App Feature / Microservice) Project** was created to:
- Simulate **real enterprise DevOps challenges**
- Build a system **incrementally**, not perfectly
- Start small â†’ evolve â†’ migrate â†’ optimize
- Document **why decisions were taken**, not just _what was done_

This project intentionally embraces **constraints**:
- Limited budget
- No domain/DNS
- Single-node Kubernetes cluster
- Manual + automated workflows
- Real failures and recovery

---

## 2ï¸âƒ£ Why Microservices Architecture?
### Why Microservices (Instead of Monolith)?
Microservices were chosen to demonstrate:
- Independent build & deploy
- Service isolation
- Kubernetes-native workflows
- Real CI/CD complexity
This mirrors how **banking and enterprise systems** are actually built.

---

## 3ï¸âƒ£ Why Only 4 AFMs (Microservices)?
The project intentionally limits itself to **four AFMs** to maintain **clarity and depth**:
### Selected AFMs:
1. **Auth Service**
2. **Registration Service**
3. **Login Service**
4. **Frontend UI (separate microservice)**    

### Why This Split?
- **Auth, Login, Registration**  
    â†’ Represent typical identity workflows in banking systems
- **Frontend UI as a separate microservice**  
    â†’ Enables:
    - Independent UI deployment
    - Backend changes without UI rebuild
    - Real ingress & routing scenarios

This is **not over-engineering**, but **controlled realism**.

---

## 4ï¸âƒ£ Why Spring Boot (Java) & HTML/CSS Frontend?
### Backend â€“ Spring Boot (Java)
Chosen because:
- Widely used in banking & enterprise systems
- Strong ecosystem
- Easy observability integration
- Realistic for interviews

### Frontend â€“ HTML/CSS (Simple)
Chosen intentionally:
- Focus stays on **DevOps**, not frontend frameworks
- Faster iteration
- Easy containerization
- Clear ingress routing demonstration

---

## 5ï¸âƒ£ Technology Stack â€“ Why Each Tool Was Chosen
### â˜ï¸ AWS â€“ Why AWS?
AWS was selected because it reflects **real enterprise adoption**.
**Services used and why:**
- **EC2** â€“ GitLab shell runner & initial hosting
- **S3** â€“ Terraform remote state
- **DynamoDB** â€“ Terraform state locking
- **ECR** â€“ Secure container registry
- **IAM** â€“ Fine-grained access control
- **CloudWatch** â€“ Infrastructure-level monitoring
- **RDS** â€“ Persistent production-style database

---

### â˜¸ï¸ Amazon EKS â€“ Why Single Node (t3.medium)?
- Budget-constrained, realistic learning setup
- Forces **capacity planning**
- Exposes pod scheduling issues
- Enables real troubleshooting
> Single-node EKS is **harder**, not easier â€” and that was intentional.

---

## 6ï¸âƒ£ GitLab for SCM & CI/CD â€“ Why?
### Why GitLab Instead of GitHub Actions / Jenkins?
- Unified SCM + CI/CD
- Enterprise-grade pipelines
- Strong support for:
    - Manual gates
    - Parameterized pipelines        
    - Multi-stage DevSecOps workflows

---

### Why EC2 t3.medium as GitLab Shell Runner?
- Needed Docker-in-Docker control
- Needed full system access
- Same host used initially for app hosting
- Reduced cost & complexity

### Challenges Faced (Will be shown later):
- Disk cleanup
- Docker daemon conflicts
- Permission issues
- Long-running pipelines

(All documented in later sections)

---

## 7ï¸âƒ£ Monorepo Strategy â€“ Why One Repo?
All AFM microservices were initially kept in a **single monorepo**.
### Why Monorepo?
- Easier dependency management
- Shared pipeline logic
- Centralized control    
- Faster iteration

### Challenge:
> How to build & deploy **only one service** without rebuilding all?

### Solution:
- **Hybrid GitLab pipeline**
- Manual inputs:
    - build = true/false
    - deploy = true/false
    - service selection
- Real enterprise-style pipeline control

---

## 8ï¸âƒ£ Terraform â€“ Infrastructure as Code
### Why Terraform?
- Cloud-agnostic IaC
- Declarative
- Enterprise standard

### Key Practices Used:
- Modular design
- Environment-aware structure
- Remote state:
    - **S3 backend**
    - **DynamoDB lock**
- No local `terraform apply`
- Infra changes only via pipeline

---

## 9ï¸âƒ£ Docker â€“ Why Still Required:
Even with Kubernetes:
- Docker is the **packaging standard**
- Enables:
    - Local testing
    - Docker Compose workflows
    - Consistent builds across environments

---

## ğŸ”Ÿ Kubernetes â€“ Why Not Just Docker Compose:
### Why Kubernetes?
Docker Compose was initially sufficient, **until**:
- Scaling was needed
- Rolling updates were needed
- Health checks mattered
- Ingress routing became complex
- Future upgrade strategies were discussed

Kubernetes enabled:
- Declarative deployments
- Self-healing
- Traffic abstraction
- Production-style operations

---

## 1ï¸âƒ£1ï¸âƒ£ HTTPS Journey â€“ Docker Compose â†’ EKS
### Phase 1: Docker Compose
- NGINX
- Self-signed certificate
- HTTPS enabled locally
- Good for early-stage validation

### Phase 2: EKS + ALB Controller
- Switched to AWS Load Balancer Controller
- Self-signed cert **not supported**
- AWS ACM not used (no DNS)
- Operated over HTTP

This shows **real constraint-based decision making**.

---

## 1ï¸âƒ£2ï¸âƒ£ Database Evolution â€“ user.json â†’ RDS
### Initial State:
- Local `/data/user.json`
- Simple & fast

### Why Changed?
- Not persistent
- Not scalable
- Not production-like

### Final State:
- Amazon RDS
- Secure access via SG
- Used by all AFMs
- Real database connectivity challenges handled

---

## 1ï¸âƒ£3ï¸âƒ£ DevSecOps â€“ Shift Left Security
### Why Security Early?
Security added **inside pipelines**, not post-deployment.
### Tools Chosen:
- **SAST** â€“ SonarQube
- **SCA / Image Scan** â€“ Trivy
- **DAST** â€“ OWASP ZAP

### Integration:
- Multi-stage GitLab pipelines
- Fail-on-critical issues
- Manual gates where needed
---

## 1ï¸âƒ£4ï¸âƒ£ Observability â€“ Why PT, GA & CloudWatch?
### CloudWatch
- Node & infra metrics
- AWS-native visibility

### Prometheus (PT)
- Kubernetes & app metrics
- Service-level monitoring

### Grafana (GA)
- Visualization
- Debugging
- Interview-grade dashboards

### Real Challenge Faced:
- Single node capacity exceeded
- 17 pods couldnâ€™t schedule
- Solution:
    - Reduced AFM replicas
    - Kept observability components minimal

---

## 1ï¸âƒ£5ï¸âƒ£ Why Separate Repos & Pipelines?
### 1. **afm-project**
- Application CI/CD
- Build, scan, deploy

### 2. **afm-infra**
- Terraform modules
- Environment-wise provisioning
- IAM, EKS, ALB

### 3. **afm-observability**
- Monitoring stack
- Metrics, dashboards
- Verification pipelines
This separation reflects **real platform teams**.

---

## 1ï¸âƒ£6ï¸âƒ£ Journey Summary (Very Important)

- Started with EC2 + Docker Compose
- Added NGINX + HTTPS
- Migrated to Kubernetes (EKS)
- Faced IAM & EKS issues
- Integrated DevSecOps
- Hit capacity limits
- Optimized pod strategy
- Built observability
- Documented everything

# ğŸ“¸ Architecture Diagrams & Screenshots
This section provides **visual evidence** of the AFM projectâ€™s architecture, pipelines, deployments, security scans, and observability setup.

> âš ï¸ Screenshots are intentionally organized **by pipeline and phase**, not randomly.  
> This mirrors how DevOps platforms are reviewed in real teams.

---

## ğŸ“ Architecture Diagrams
### 1ï¸âƒ£ High-Level System Architecture
**Description:**
- User â†’ ALB â†’ EKS â†’ AFM Microservices â†’ RDS
- Clear separation of Infra, App, Security, Observability

`![AFM High-Level Architecture](diagrams/afm-high-level-architecture.png)`

ğŸ“Œ _Diagram will include_:
- AWS VPC
- EKS single-node cluster
- ALB Controller
- AFM microservices
- RDS
- Monitoring stack

---

### 2ï¸âƒ£ CI/CD Architecture (GitLab-Centric)
**Description:**
- Separate pipelines for:
    - afm-project
    - afm-infra
    - afm-observability
- Security and monitoring integrated

`![AFM CI/CD Architecture](diagrams/afm-cicd-architecture.png)`

---

## ğŸ§± Infrastructure Pipeline Screenshots (afm-infra)
## ğŸ”¹ AFM Infra Pipeline â€“ Terraform & EKS Provisioning

Infrastructure provisioning in the AFM project is handled **exclusively through a GitLab CI/CD pipeline**, following production-grade DevOps practices.

### ğŸ”¸ Pipeline Design Highlights
- Environment-driven execution (`dev | test | devops | prod`)
- No local `terraform apply`
- Manual control over destructive actions
- Safe, auditable infrastructure changes

---

### ğŸ”¸ Pipeline Inputs (Environment & Controls)

The pipeline is parameterized to allow **controlled execution** of each Terraform stage.

`![Infra Pipeline Inputs](screenshots/afm-infra/pipeline-inputs.PNG)`

**Inputs include:**
- `environment` â€“ target environment
- `run_validate` â€“ Terraform validation
- `run_plan` â€“ Infrastructure planning
- `run_apply` â€“ Apply changes (manual)
- `run_destroy` â€“ Controlled teardown

This prevents accidental infrastructure changes.

---

### ğŸ”¸ Terraform Validate Stage
`![Terraform Validate](screenshots/afm-infra/terraform-validate.png)`
- Syntax and configuration validation
- Early failure detection
- No cloud changes

---

### ğŸ”¸ Terraform Plan Stage
`![Terraform Plan](screenshots/afm-infra/terraform-plan.png)`
- Shows exact resources to be created or modified
- Environment-aware planning
- Acts as a change preview for review

---

### ğŸ”¸ Manual Approval Gate
`![Manual Approval](screenshots/afm-infra/manual-approval.png)`
- Terraform apply requires explicit approval
- Prevents accidental cluster creation or deletion
- Mirrors enterprise change-management workflows

---

### ğŸ”¸ Terraform Apply â€“ EKS Provisioning

`![Terraform Apply](screenshots/afm-infra/terraform-apply.png)`
- Provisions:
    - EKS single-node cluster (t3.medium)
    - IAM roles and policies
    - ALB controller prerequisites
- Fully automated, pipeline-driven execution

---

### ğŸ”¸ Why This Matters (Interview Angle)
This pipeline demonstrates:
- Infrastructure as Code maturity
- Safe production workflows
- Environment isolation
- Audit-friendly DevOps execution
---

## ğŸš€ Application Pipeline Screenshots (afm-project)
### 6ï¸âƒ£ Hybrid GitLab Pipeline Inputs
`![Hybrid Pipeline Inputs](screenshots/afm-project/hybrid-pipeline-inputs.png)`
**Shows:**
- Build toggle
- Deploy toggle
- Single-service selection
- Monorepo challenge solution

---

### 7ï¸âƒ£ Docker Build & Push to ECR
`![Docker Build Push](screenshots/afm-project/docker-build-push.png)`

---

### 8ï¸âƒ£ Kubernetes Deployment Rollout
`![K8s Deployment](screenshots/afm-project/k8s-deployment.png)`

**Shows:**
- Rolling updates
- Zero downtime behavior
- Pod recreation

---

### 9ï¸âƒ£ ALB Ingress Routing
`![ALB Ingress](screenshots/afm-project/alb-ingress.png)`
**Highlights:**
- Path-based routing
- Service-level exposure
- HTTP traffic via ALB

---

## ğŸ” DevSecOps Screenshots
### ğŸ”Ÿ SonarQube â€“ SAST Scan
`![SonarQube Scan](screenshots/security/sonarqube-scan.png)`
---

### 1ï¸âƒ£1ï¸âƒ£ Trivy â€“ Image Vulnerability Scan

`![Trivy Scan](screenshots/security/trivy-scan.png)`

---

### 1ï¸âƒ£2ï¸âƒ£ OWASP ZAP â€“ DAST Scan
`![OWASP ZAP Scan](screenshots/security/zap-scan.png)`

**Shows:**

- Runtime security testing
- Pipeline-integrated DAST
- Shift-left security implementation

---

## ğŸ“Š Observability Screenshots (afm-observability)
### 1ï¸âƒ£3ï¸âƒ£ Prometheus Targets & ServiceMonitors

`![Prometheus Targets](screenshots/observability/prometheus-targets.png)`

---

### 1ï¸âƒ£4ï¸âƒ£ Grafana Dashboards

`![Grafana Dashboard](screenshots/observability/grafana-dashboard.png)`

---

### 1ï¸âƒ£5ï¸âƒ£ CloudWatch Metrics

`![CloudWatch Metrics](screenshots/observability/cloudwatch-metrics.png)`

---

## âš ï¸ Real Issues & Constraints (Visual Proof)

### 1ï¸âƒ£6ï¸âƒ£ Pod Scheduling Failure (Capacity Exceeded)

`![Pod Scheduling Issue](screenshots/issues/pod-scheduling-failure.png)`

**Explanation:**
- Single-node cluster
- 17 pods
- Insufficient CPU/memory
- Real production-style limitation

---

### 1ï¸âƒ£7ï¸âƒ£ Resolution â€“ Replica Optimization

`![Replica Fix](screenshots/issues/replica-optimization.png)`

**Shows:**
- Reduced replicas
- Successful scheduling
- Stability restored
